<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>线性回归算法 | LiLi&#39;s Journey in Machine Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="第四章 线性回归算法1. 载入分析所需要的模块和函数#载入分析所需要的模块和函数 12345678910import pandas as pd#载入pandas模块，并简称为pdimport numpy as np#载入numpy模块，并简称为npimport matplotlib.pyplot as plt#载入matplotlib.pyplot模块，并简称为pltimport seaborn">
<meta property="og:type" content="article">
<meta property="og:title" content="线性回归算法">
<meta property="og:url" content="https://sxdtlili.github.io/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="LiLi&#39;s Journey in Machine Learning">
<meta property="og:description" content="第四章 线性回归算法1. 载入分析所需要的模块和函数#载入分析所需要的模块和函数 12345678910import pandas as pd#载入pandas模块，并简称为pdimport numpy as np#载入numpy模块，并简称为npimport matplotlib.pyplot as plt#载入matplotlib.pyplot模块，并简称为pltimport seaborn">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-03-20T16:05:18.000Z">
<meta property="article:modified_time" content="2024-03-20T16:46:01.905Z">
<meta property="article:author" content="LiLi">
<meta property="article:tag" content="线性回归">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="LiLi's Journey in Machine Learning" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LiLi&#39;s Journey in Machine Learning</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://sxdtlili.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-线性回归算法" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/" class="article-date">
  <time class="dt-published" datetime="2024-03-20T16:05:18.000Z" itemprop="datePublished">2024-03-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/">算法实现</a>►<a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      线性回归算法
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="第四章-线性回归算法"><a href="#第四章-线性回归算法" class="headerlink" title="第四章 线性回归算法"></a>第四章 线性回归算法</h1><h2 id="1-载入分析所需要的模块和函数"><a href="#1-载入分析所需要的模块和函数" class="headerlink" title="1. 载入分析所需要的模块和函数"></a>1. 载入分析所需要的模块和函数</h2><p>#载入分析所需要的模块和函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd#载入pandas模块，并简称为pd</span><br><span class="line">import numpy as np#载入numpy模块，并简称为np</span><br><span class="line">import matplotlib.pyplot as plt#载入matplotlib.pyplot模块，并简称为plt</span><br><span class="line">import seaborn as sns#载入seaborn模块，并简称为sns</span><br><span class="line">from scipy import stats#载入stats模块</span><br><span class="line">from scipy.stats import probplot#载入probplot模块</span><br><span class="line">import statsmodels.formula.api as smf#载入statsmodels.formula.api模块，并简称为smf</span><br><span class="line">from sklearn.linear_model import LinearRegression#载入LinearRegression模块</span><br><span class="line">from sklearn.model_selection import train_test_split#载入train_test_split模块</span><br><span class="line">from sklearn.metrics import mean_squared_error, r2_score#载入mean_squared_error, r2_score模块</span><br></pre></td></tr></table></figure>
<h2 id="2-数据读取及观察"><a href="#2-数据读取及观察" class="headerlink" title="2. 数据读取及观察"></a>2. 数据读取及观察</h2><p>#习题1<br>#数据读取及观察</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data=pd.read_csv(&#x27;D:/2023-2024-1/专业学习/机器学习原理与算法实现/Python机器学习原理与算法实现之PPT与源代码/正文源代码及数据文件/第四章 线性回归算法/数据4.2.csv&#x27;)</span><br><span class="line">data= data.iloc[:, 1:5]#提取M0流通中现金，M1狭义货币，M2广义货币三列</span><br></pre></td></tr></table></figure>
<h2 id="3-描述性分析"><a href="#3-描述性分析" class="headerlink" title="3. 描述性分析"></a>3. 描述性分析</h2><h3 id="3-1-对数据集进行描述性分析"><a href="#3-1-对数据集进行描述性分析" class="headerlink" title="3.1 对数据集进行描述性分析"></a>3.1 对数据集进行描述性分析</h3><p>#描述性分析</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data.describe()#对数据集进行描述性分析</span><br><span class="line"></span><br><span class="line">data.describe().round(2)#只保留两位小数</span><br></pre></td></tr></table></figure>

<h3 id="3-2-对数据进行转置"><a href="#3-2-对数据进行转置" class="headerlink" title="3.2 对数据进行转置"></a>3.2 对数据进行转置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data.describe().round(2).T#只保留两位小数并转置</span><br></pre></td></tr></table></figure>

<h3 id="3-3-对数据集中的变量求均值"><a href="#3-3-对数据集中的变量求均值" class="headerlink" title="3.3 对数据集中的变量求均值"></a>3.3 对数据集中的变量求均值</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data.mean()#对数据集中的变量求均值</span><br></pre></td></tr></table></figure>

<h3 id="3-4-对数据集中的变量求方差"><a href="#3-4-对数据集中的变量求方差" class="headerlink" title="3.4 对数据集中的变量求方差"></a>3.4 对数据集中的变量求方差</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data.var()#对数据集中的变量求方差</span><br></pre></td></tr></table></figure>

<h3 id="3-5-对数据集中的变量求标准差"><a href="#3-5-对数据集中的变量求标准差" class="headerlink" title="3.5 对数据集中的变量求标准差"></a>3.5 对数据集中的变量求标准差</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.std()#对数据集中的变量求标准差</span><br></pre></td></tr></table></figure>

<h3 id="3-6-对数据集中的变量求协方差矩阵"><a href="#3-6-对数据集中的变量求协方差矩阵" class="headerlink" title="3.6 对数据集中的变量求协方差矩阵"></a>3.6 对数据集中的变量求协方差矩阵</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data.cov()#对数据集中的变量求协方差矩阵</span><br></pre></td></tr></table></figure>

<h2 id="4-正态性检验"><a href="#4-正态性检验" class="headerlink" title="4. 正态性检验"></a>4. 正态性检验</h2><h3 id="4-1-Shapiro-Wilk-test检验"><a href="#4-1-Shapiro-Wilk-test检验" class="headerlink" title="4.1 Shapiro-Wilk test检验"></a>4.1 Shapiro-Wilk test检验</h3><p>#Shapiro-Wilk test检验</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Ho = &#x27;数据服从正态分布&#x27;#定义原假设</span><br><span class="line">Ha = &#x27;数据不服从正态分布&#x27;#定义备择假设</span><br><span class="line">alpha = 0.05#定义显著性P值</span><br><span class="line">def normality_check(data):</span><br><span class="line">    for columnName, columnData in data.items():</span><br><span class="line">        print(&quot;Shapiro test for &#123;columnName&#125;&quot;.format(columnName=columnName))</span><br><span class="line">        res = stats.shapiro(columnData)</span><br><span class="line">        pValue = round(res[1], 2)</span><br><span class="line">        if pValue &gt; alpha:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &gt; &#123;alpha&#125;. 不能拒绝原假设. &#123;Ho&#125;&quot;.format(pValue=pValue, alpha=alpha, Ho=Ho))</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &lt;= &#123;alpha&#125;. 拒绝原假设. &#123;Ha&#125;&quot;.format(pValue=pValue, alpha=alpha, Ha=Ha))</span><br><span class="line">normality_check(data)</span><br></pre></td></tr></table></figure>
<h3 id="4-2-使用kstest检验数据是否服从正态分布"><a href="#4-2-使用kstest检验数据是否服从正态分布" class="headerlink" title="4.2 使用kstest检验数据是否服从正态分布"></a>4.2 使用kstest检验数据是否服从正态分布</h3><p>#使用kstest检验数据是否服从正态分布</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Ho = &#x27;数据服从正态分布&#x27;#定义原假设</span><br><span class="line">Ha = &#x27;数据不服从正态分布&#x27;#定义备择假设</span><br><span class="line">alpha = 0.05#定义显著性P值</span><br><span class="line">def normality_check(data):</span><br><span class="line">    for columnName, columnData in data.items():</span><br><span class="line">        print(&quot;kstest for &#123;columnName&#125;&quot;.format(columnName=columnName))</span><br><span class="line">        res = stats.kstest(columnData,&#x27;norm&#x27;)</span><br><span class="line">        pValue = round(res[1], 2)</span><br><span class="line">        if pValue &gt; alpha:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &gt; &#123;alpha&#125;. 不能拒绝原假设. &#123;Ho&#125;&quot;.format(pValue=pValue, alpha=alpha, Ho=Ho))</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &lt;= &#123;alpha&#125;. 拒绝原假设. &#123;Ha&#125;&quot;.format(pValue=pValue, alpha=alpha, Ha=Ha))</span><br><span class="line">normality_check(data)</span><br></pre></td></tr></table></figure>
<h2 id="5-作图"><a href="#5-作图" class="headerlink" title="5 作图"></a>5 作图</h2><h3 id="5-1-直方图"><a href="#5-1-直方图" class="headerlink" title="5.1 直方图"></a>5.1 直方图</h3><h1 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(16, 9),dpi=300)</span><br><span class="line">sns.histplot(data[&#x27;M0&#x27;],bins=10,kde=True)</span><br><span class="line">plt.title(&quot;Histogram of &#x27;M0&#x27;&quot;)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(16, 9),dpi=300)</span><br><span class="line">sns.histplot(data[&#x27;M1&#x27;],bins=10,kde=True)</span><br><span class="line">plt.title(&quot;Histogram of &#x27;M1&#x27;&quot;)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(16, 9),dpi=300)</span><br><span class="line">sns.histplot(data[&#x27;M2&#x27;],bins=10,kde=True)</span><br><span class="line">plt.title(&quot;Histogram of &#x27;M2&#x27;&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="5-2-密度图"><a href="#5-2-密度图" class="headerlink" title="5.2 密度图"></a>5.2 密度图</h3><p>#密度图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(12, 6),dpi=300)</span><br><span class="line">plt.subplot(1,3,1)#指定作图位置</span><br><span class="line">sns.histplot(data[&#x27;M0&#x27;], kde=True)</span><br><span class="line">plt.title(&quot;Density distribution of &#x27;M0&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,2)#指定作图位置</span><br><span class="line">sns.histplot(data[&#x27;M1&#x27;], kde=True)</span><br><span class="line">plt.title(&quot;Density distribution of &#x27;M1&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,3)#指定作图位置</span><br><span class="line">sns.histplot(data[&#x27;M2&#x27;], kde=True)</span><br><span class="line">plt.title(&quot;Density distribution of &#x27;M2&#x27;&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="5-3-箱线图"><a href="#5-3-箱线图" class="headerlink" title="5.3 箱线图"></a>5.3 箱线图</h3><p>#箱线图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(14, 6),dpi=300)</span><br><span class="line">plt.subplot(1,3,1)#指定作图位置</span><br><span class="line">plt.boxplot(data[&#x27;M0&#x27;])</span><br><span class="line">plt.title(&quot;Boxlpot of &#x27;M0&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,2)#指定作图位置</span><br><span class="line">plt.boxplot(data[&#x27;M1&#x27;])</span><br><span class="line">plt.title(&quot;Boxlpot of &#x27;M1&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,3)#指定作图位置</span><br><span class="line">plt.boxplot(data[&#x27;M2&#x27;])</span><br><span class="line">plt.title(&quot;Boxlpot of &#x27;M2&#x27;&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="5-4-小提琴图"><a href="#5-4-小提琴图" class="headerlink" title="5.4 小提琴图"></a>5.4 小提琴图</h3><p>#小提琴图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(16, 6),dpi=300)</span><br><span class="line">plt.subplot(1,3,1)#指定作图位置</span><br><span class="line">sns.violinplot(data[&#x27;M0&#x27;])</span><br><span class="line">plt.title(&quot;Violin plot of &#x27;M0&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,2)#指定作图位置</span><br><span class="line">sns.violinplot(data[&#x27;M1&#x27;])</span><br><span class="line">plt.title(&quot;Violin plot of &#x27;M1&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,3)#指定作图位置</span><br><span class="line">sns.violinplot(data[&#x27;M2&#x27;])</span><br><span class="line">plt.title(&quot;Violin plot of &#x27;M2&#x27;&quot;)</span><br></pre></td></tr></table></figure>

<h3 id="5-5-正态-QQ-图"><a href="#5-5-正态-QQ-图" class="headerlink" title="5.5 正态 QQ 图"></a>5.5 正态 QQ 图</h3><p>#正态 QQ 图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(16, 6),dpi=300)</span><br><span class="line">plt.subplot(1,3,1)#指定作图位置</span><br><span class="line">probplot(data[&#x27;M0&#x27;], plot=plt)</span><br><span class="line">plt.title(&quot;Q-Q plot of &#x27;M0&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,2)#指定作图位置</span><br><span class="line">probplot(data[&#x27;M1&#x27;], plot=plt)</span><br><span class="line">plt.title(&quot;Q-Q plot of &#x27;M1&#x27;&quot;)</span><br><span class="line">plt.subplot(1,3,3)#指定作图位置</span><br><span class="line">probplot(data[&#x27;M2&#x27;], plot=plt)</span><br><span class="line">plt.title(&quot;Q-Q plot of &#x27;M2&#x27;&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="5-6-散点图和点线图"><a href="#5-6-散点图和点线图" class="headerlink" title="5.6 散点图和点线图"></a>5.6 散点图和点线图</h3><h1 id="散点图和点线图"><a href="#散点图和点线图" class="headerlink" title="散点图和点线图"></a>散点图和点线图</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(16,6),dpi=300)#设定图形的宽为12英寸，图形的高为6英寸</span><br><span class="line">plt.subplot(1,3,1)#指定作图位置。在同一画面创建1行3列个图形位置，首先在从左到右的第一个位置作图</span><br><span class="line">sns.scatterplot(data=data, x=&quot;M1&quot;, y=&quot;M2&quot;, hue=&quot;M1&quot;, alpha=0.6)</span><br><span class="line">plt.title(&quot;Scatter plot&quot;)#将散点图的标题设定为Scatter plot</span><br><span class="line"></span><br><span class="line">plt.subplot(1,3,2)#指定作图位置</span><br><span class="line">sns.lineplot(data=data, x=&quot;M1&quot;, y=&quot;M2&quot;)</span><br><span class="line">plt.title(&quot;Line plot of M1, M2&quot;)</span><br><span class="line"></span><br><span class="line">plt.subplot(1,3,3)#指定作图位置</span><br><span class="line">sns.lineplot(data=data)#绘制全部变量的线图</span><br><span class="line">plt.title(&#x27;Line Plot&#x27;)#将标题设定为Line Plot</span><br></pre></td></tr></table></figure>
<h3 id="5-7-热力图"><a href="#5-7-热力图" class="headerlink" title="5.7 热力图"></a>5.7 热力图</h3><p>#热力图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(10, 10),dpi=300)#设置图形大小</span><br><span class="line">plt.subplot(1, 2, 1)#指定作图位置</span><br><span class="line">sns.heatmap(data=data, cmap=&quot;YlGnBu&quot;, annot = True)#基于data数据绘制热力图，cmap=&quot;YlGnBu&quot;用来设置热力图的颜色色系，annot=True表示在热力图每个方格写入数据。</span><br><span class="line">plt.title(&quot;Heatmap using seaborn&quot;)#指定作图标题</span><br><span class="line">plt.subplot(1, 2, 2)#指定作图位置</span><br><span class="line">plt.imshow(data, cmap =&quot;YlGnBu&quot;)#实现热图绘制</span><br><span class="line">plt.title(&quot;Heatmap using matplotlib&quot;)#指定作图标题</span><br></pre></td></tr></table></figure>
<h2 id="6-回归拟合图"><a href="#6-回归拟合图" class="headerlink" title="6 回归拟合图"></a>6 回归拟合图</h2><p>#回归拟合图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(10, 10),dpi=300)#设置图形大小</span><br><span class="line">sns.regplot( x=&quot;M0&quot;, y=&quot;M1&quot;,data=data )</span><br></pre></td></tr></table></figure>
<h2 id="7-联合分布图"><a href="#7-联合分布图" class="headerlink" title="7 联合分布图"></a>7 联合分布图</h2><p>#联合分布图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(8, 6),dpi=100)#设置图形大小</span><br><span class="line">sns.jointplot(x = &quot;M0&quot;, y = &quot;M1&quot;, kind = &quot;reg&quot;, data = data)</span><br><span class="line">plt.title(&quot;Joint plot using sns&quot;)#为图表设置标题</span><br></pre></td></tr></table></figure>
<p>#习题2<br>#数据读取及观察</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data=pd.read_csv(&#x27;D:/2023-2024-1/专业学习/机器学习原理与算法实现/Python机器学习原理与算法实现之PPT与源代码/正文源代码及数据文件/第四章 线性回归算法/数据4.3.csv&#x27;)</span><br><span class="line">data= data.iloc[:, 1:6]#提取Profit contribution，Net interest income，Intermediate income，Deposit and finance daily列</span><br></pre></td></tr></table></figure>
<p>#描述性分析</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">data.describe()#对数据集进行描述性分析</span><br><span class="line"></span><br><span class="line">data.describe().round(2)#只保留两位小数</span><br><span class="line"></span><br><span class="line">data.describe().round(2).T#只保留两位小数并转置</span><br><span class="line"></span><br><span class="line">data.mean()#对数据集中的变量求均值</span><br><span class="line"></span><br><span class="line">data.var()#对数据集中的变量求方差</span><br><span class="line"></span><br><span class="line">data.std()#对数据集中的变量求标准差</span><br><span class="line"></span><br><span class="line">data.cov()#对数据集中的变量求协方差矩阵</span><br></pre></td></tr></table></figure>
<p>#Shapiro-Wilk test检验</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Ho = &#x27;数据服从正态分布&#x27;#定义原假设</span><br><span class="line">Ha = &#x27;数据不服从正态分布&#x27;#定义备择假设</span><br><span class="line">alpha = 0.05#定义显著性P值</span><br><span class="line">def normality_check(data):</span><br><span class="line">    for columnName, columnData in data.items():</span><br><span class="line">        print(&quot;Shapiro test for &#123;columnName&#125;&quot;.format(columnName=columnName))</span><br><span class="line">        res = stats.shapiro(columnData)</span><br><span class="line">        pValue = round(res[1], 2)</span><br><span class="line">        if pValue &gt; alpha:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &gt; &#123;alpha&#125;. 不能拒绝原假设. &#123;Ho&#125;&quot;.format(pValue=pValue, alpha=alpha, Ho=Ho))</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &lt;= &#123;alpha&#125;. 拒绝原假设. &#123;Ha&#125;&quot;.format(pValue=pValue, alpha=alpha, Ha=Ha))</span><br><span class="line">normality_check(data)</span><br></pre></td></tr></table></figure>
<p>#使用kstest检验数据是否服从正态分布</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Ho = &#x27;数据服从正态分布&#x27;#定义原假设</span><br><span class="line">Ha = &#x27;数据不服从正态分布&#x27;#定义备择假设</span><br><span class="line">alpha = 0.05#定义显著性P值</span><br><span class="line">def normality_check(data):</span><br><span class="line">    for columnName, columnData in data.items():</span><br><span class="line">        print(&quot;kstest for &#123;columnName&#125;&quot;.format(columnName=columnName))</span><br><span class="line">        res = stats.kstest(columnData,&#x27;norm&#x27;)</span><br><span class="line">        pValue = round(res[1], 2)</span><br><span class="line">        if pValue &gt; alpha:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &gt; &#123;alpha&#125;. 不能拒绝原假设. &#123;Ho&#125;&quot;.format(pValue=pValue, alpha=alpha, Ho=Ho))</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;pvalue = &#123;pValue&#125; &lt;= &#123;alpha&#125;. 拒绝原假设. &#123;Ha&#125;&quot;.format(pValue=pValue, alpha=alpha, Ha=Ha))</span><br><span class="line">normality_check(data)</span><br></pre></td></tr></table></figure>
<h2 id="8-相关性分析"><a href="#8-相关性分析" class="headerlink" title="8 相关性分析"></a>8 相关性分析</h2><h3 id="8-1-皮尔逊相关系数矩阵"><a href="#8-1-皮尔逊相关系数矩阵" class="headerlink" title="8.1 皮尔逊相关系数矩阵"></a>8.1 皮尔逊相关系数矩阵</h3><p>#相关性分析</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.set_option(&#x27;display.max_rows&#x27;, None)#显示完整的行，如果不运行该代码，那么结果的行可能会显示不全，中间有省略号。</span><br><span class="line">pd.set_option(&#x27;display.max_columns&#x27;, None)#显示完整的列，如果不运行该代码，那么结果的列可能会显示不全，中间有省略号。</span><br><span class="line">print(data.corr(method=&#x27;pearson&#x27;)) #输出变量之间的皮尔逊相关系数矩阵</span><br></pre></td></tr></table></figure>
<h3 id="8-2-绘制相关矩阵的热图"><a href="#8-2-绘制相关矩阵的热图" class="headerlink" title="8.2 绘制相关矩阵的热图"></a>8.2 绘制相关矩阵的热图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(8, 6),dpi=100)#设置图形大小</span><br><span class="line">plt.subplot(1,1,1)</span><br><span class="line">sns.heatmap(data.corr(), annot=True)# 绘制相关矩阵的热图</span><br></pre></td></tr></table></figure>
<h3 id="8-3-斯皮尔曼等级相关系数矩阵"><a href="#8-3-斯皮尔曼等级相关系数矩阵" class="headerlink" title="8.3 斯皮尔曼等级相关系数矩阵"></a>8.3 斯皮尔曼等级相关系数矩阵</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(data.corr(method=&#x27;spearman&#x27;)) #输出变量之间的斯皮尔曼等级相关系数矩阵</span><br></pre></td></tr></table></figure>
<h3 id="8-4-肯德尔等级相关系数矩阵"><a href="#8-4-肯德尔等级相关系数矩阵" class="headerlink" title="8.4 肯德尔等级相关系数矩阵"></a>8.4 肯德尔等级相关系数矩阵</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(data.corr(method=&#x27;kendall&#x27;)) #输出变量之间的肯德尔等级相关系数矩阵</span><br></pre></td></tr></table></figure>
<h2 id="9-使用-smf-进行线性回归"><a href="#9-使用-smf-进行线性回归" class="headerlink" title="9 使用 smf 进行线性回归"></a>9 使用 smf 进行线性回归</h2><p>#使用 smf 进行线性回归</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = data.iloc[:, 1:5]</span><br><span class="line">y = data.iloc[:, 0:1]</span><br><span class="line">model = smf.ols(&#x27;y~X&#x27;, data=data).fit()#使用线性回归模型，并进行训练</span><br><span class="line">print(model.summary())#输出估计模型摘要</span><br></pre></td></tr></table></figure>
<p>这是一个OLS（普通最小二乘法）回归结果的摘要。OLS是一种用于估计回归模型参数的统计方法。</p>
<ol>
<li>R-squared（R平方）: 0.279，这表示模型可以解释因变量变化的27.9%。</li>
<li>Adj. R-squared（调整后的R平方）: 0.278，这是对R平方的修正，考虑了模型中自变量的数量和样本量的影响。</li>
<li>F-statistic（F统计量）: 1086.0，用于检验模型的整体显著性。</li>
<li>Prob (F-statistic)（F统计量的概率）: 0.00，表示模型的整体显著性的概率。</li>
<li>coef（系数）列包含了每个自变量的系数估计值，std err列是系数的标准误差。</li>
<li>P&gt;|t|列显示了每个系数的显著性，即它们是否显著地不同于零。</li>
<li>Omnibus（奥姆尼巴斯）: 26383.785，用于检验误差项的正态性。</li>
<li>Prob(Omnibus)（奥姆尼巴斯的概率）: 0.000，表示误差项正态性的概率。</li>
<li>Skew（偏度）: -48.654，表示因变量的偏度。</li>
<li>Kurtosis（峰度）: 3222.836，表示因变量的峰度。</li>
<li>Durbin-Watson（杜宾-沃森统计量）: 1.999，用于检验误差项之间的自相关性。</li>
<li>Jarque-Bera（雅可比-贝拉）: 3649612011.153，用于检验误差项的正态性。</li>
<li>Cond. No.（条件数）: 3.87e+07，用于检验自变量之间的多重共线性。<br>– 需要注意的是，标准误差假设误差项的协方差矩阵被正确地指定。条件数很大可能表明存在严重的多重共线性或其他数值问题。</li>
</ol>
<h2 id="10-多重共线性检验"><a href="#10-多重共线性检验" class="headerlink" title="10 多重共线性检验"></a>10 多重共线性检验</h2><p>#多重共线性检验 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from statsmodels.stats.outliers_influence import variance_inflation_factor</span><br><span class="line">vif = pd.DataFrame()</span><br><span class="line">vif[&quot;VIF Factor&quot;] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]</span><br><span class="line">vif[&quot;features&quot;] = X.columns</span><br><span class="line">vif.round(1)</span><br></pre></td></tr></table></figure>
<h2 id="11-使用-sklearn-进行线性回归"><a href="#11-使用-sklearn-进行线性回归" class="headerlink" title="11 使用 sklearn 进行线性回归"></a>11 使用 sklearn 进行线性回归</h2><h3 id="11-1-使用验证集法进行模型拟合"><a href="#11-1-使用验证集法进行模型拟合" class="headerlink" title="11.1 使用验证集法进行模型拟合"></a>11.1 使用验证集法进行模型拟合</h3><p>#使用 sklearn 进行线性回归<br>#使用验证集法进行模型拟合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = data.iloc[:, 1:5]</span><br><span class="line">y = data.iloc[:, 0:1]</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)#将样本示例全集划分为训练样本和测试样本，测试样本占比为30%。</span><br><span class="line">X_train.shape, X_test.shape, y_train.shape, y_test.shape#观察四个数据的形状</span><br><span class="line">model = LinearRegression()#使用线性回归模型</span><br><span class="line">model.fit(X_train, y_train)#基于训练样本拟合模型</span><br></pre></td></tr></table></figure>
<h3 id="11-2-计算回归系数值"><a href="#11-2-计算回归系数值" class="headerlink" title="11.2 计算回归系数值"></a>11.2 计算回归系数值</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.coef_#计算上步估计得到的回归系数值</span><br></pre></td></tr></table></figure>
<h3 id="11-3-模型在训练集中的拟合优度（可决系数）"><a href="#11-3-模型在训练集中的拟合优度（可决系数）" class="headerlink" title="11.3 模型在训练集中的拟合优度（可决系数）"></a>11.3 模型在训练集中的拟合优度（可决系数）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.score(X_train, y_train)#观察模型在训练集中的拟合优度（可决系数）</span><br></pre></td></tr></table></figure>
<h3 id="11-4-响应变量基于测试集的预测结果"><a href="#11-4-响应变量基于测试集的预测结果" class="headerlink" title="11.4 响应变量基于测试集的预测结果"></a>11.4 响应变量基于测试集的预测结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pred = model.predict(X_test)#计算响应变量基于测试集的预测结果</span><br><span class="line">pred.shape#观察数据形状</span><br></pre></td></tr></table></figure>
<h3 id="11-5-测试集的均方误差"><a href="#11-5-测试集的均方误差" class="headerlink" title="11.5 测试集的均方误差"></a>11.5 测试集的均方误差</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mean_squared_error(y_test, pred)#计算测试集的均方误差</span><br></pre></td></tr></table></figure>
<h3 id="11-6-计算测试集的可决系数"><a href="#11-6-计算测试集的可决系数" class="headerlink" title="11.6 计算测试集的可决系数"></a>11.6 计算测试集的可决系数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_score(y_test, pred)#计算测试集的可决系数</span><br></pre></td></tr></table></figure>
<h3 id="11-7-更换随机数种子，使用验证集法进行模型拟合"><a href="#11-7-更换随机数种子，使用验证集法进行模型拟合" class="headerlink" title="11.7 更换随机数种子，使用验证集法进行模型拟合"></a>11.7 更换随机数种子，使用验证集法进行模型拟合</h3><p>#更换随机数种子，使用验证集法进行模型拟合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)#更换随机数种子</span><br><span class="line">model = LinearRegression().fit(X_train, y_train)#基于训练样本拟合线性回归模型</span><br><span class="line">pred = model.predict(X_test)#计算响应变量基于测试集的预测结果</span><br><span class="line">mean_squared_error(y_test, pred)#计算测试集的均方误差</span><br><span class="line"></span><br><span class="line">r2_score(y_test, pred)#计算测试集的可决系数</span><br></pre></td></tr></table></figure>
<h2 id="12-使用10折交叉验证法进行模型拟合"><a href="#12-使用10折交叉验证法进行模型拟合" class="headerlink" title="12 使用10折交叉验证法进行模型拟合"></a>12 使用10折交叉验证法进行模型拟合</h2><h3 id="12-1-使用10折交叉验证法进行模型拟合"><a href="#12-1-使用10折交叉验证法进行模型拟合" class="headerlink" title="12.1 使用10折交叉验证法进行模型拟合"></a>12.1 使用10折交叉验证法进行模型拟合</h3><h1 id="使用10折交叉验证法进行模型拟合"><a href="#使用10折交叉验证法进行模型拟合" class="headerlink" title="使用10折交叉验证法进行模型拟合"></a>使用10折交叉验证法进行模型拟合</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import KFold</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">from sklearn.model_selection import LeaveOneOut</span><br><span class="line">from sklearn.model_selection import RepeatedKFold</span><br><span class="line">X = data.iloc[:, 1:5]</span><br><span class="line">y = data.iloc[:, 0:1]</span><br><span class="line">model = LinearRegression()#使用线性回归模型</span><br><span class="line">kfold = KFold(n_splits=10,shuffle=True, random_state=1)#将样本示例全集分为10折</span><br><span class="line">scores = cross_val_score(model, X, y, cv=kfold)#计算每一折的可决系数</span><br></pre></td></tr></table></figure>
<h3 id="12-2-显示每一折的可决系数"><a href="#12-2-显示每一折的可决系数" class="headerlink" title="12.2 显示每一折的可决系数"></a>12.2 显示每一折的可决系数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores#显示每一折的可决系数</span><br></pre></td></tr></table></figure>
<h3 id="12-3-计算各折样本可决系数的均值"><a href="#12-3-计算各折样本可决系数的均值" class="headerlink" title="12.3 计算各折样本可决系数的均值"></a>12.3 计算各折样本可决系数的均值</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores.mean()#计算各折样本可决系数的均值</span><br></pre></td></tr></table></figure>
<h3 id="12-4-计算各折样本可决系数的标准差"><a href="#12-4-计算各折样本可决系数的标准差" class="headerlink" title="12.4 计算各折样本可决系数的标准差"></a>12.4 计算各折样本可决系数的标准差</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores.std()#计算各折样本可决系数的标准差</span><br></pre></td></tr></table></figure>
<h3 id="12-5-显示各折样本的均方误差"><a href="#12-5-显示各折样本的均方误差" class="headerlink" title="12.5 显示各折样本的均方误差"></a>12.5 显示各折样本的均方误差</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores_mse = -cross_val_score(model, X, y, cv=kfold, scoring=&#x27;neg_mean_squared_error&#x27;)#得到每个子样本的均方误差</span><br><span class="line">scores_mse#显示各折样本的均方误差</span><br></pre></td></tr></table></figure>
<h3 id="12-6-各折样本均方误差的均值"><a href="#12-6-各折样本均方误差的均值" class="headerlink" title="12.6 各折样本均方误差的均值"></a>12.6 各折样本均方误差的均值</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores_mse.mean()#计算各折样本均方误差的均值</span><br></pre></td></tr></table></figure>
<h3 id="12-7-更换随机数种子观察均方误差MSE大小"><a href="#12-7-更换随机数种子观察均方误差MSE大小" class="headerlink" title="12.7 更换随机数种子观察均方误差MSE大小"></a>12.7 更换随机数种子观察均方误差MSE大小</h3><h1 id="更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小"><a href="#更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小" class="headerlink" title="更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小"></a>更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kfold = KFold(n_splits=10, shuffle=True, random_state=100)</span><br><span class="line">scores_mse = -cross_val_score(model, X, y, cv=kfold, scoring=&#x27;neg_mean_squared_error&#x27;)#得到每个子样本的均方误差</span><br><span class="line">scores_mse.mean()#计算各折样本均方误差的均值</span><br></pre></td></tr></table></figure>
<h2 id="13-使用10折重复10次交叉验证法进行模型拟合"><a href="#13-使用10折重复10次交叉验证法进行模型拟合" class="headerlink" title="13 使用10折重复10次交叉验证法进行模型拟合"></a>13 使用10折重复10次交叉验证法进行模型拟合</h2><p>#使用10折重复10次交叉验证法进行模型拟合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rkfold = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)</span><br><span class="line">scores_mse = -cross_val_score(model, X, y, cv=rkfold, scoring=&#x27;neg_mean_squared_error&#x27;)#得到每个子样本的均方误差</span><br><span class="line">scores_mse.shape</span><br><span class="line"></span><br><span class="line">scores_mse.mean()</span><br></pre></td></tr></table></figure>
<h2 id="14-使用留一交叉验证法进行模型拟合"><a href="#14-使用留一交叉验证法进行模型拟合" class="headerlink" title="14 使用留一交叉验证法进行模型拟合"></a>14 使用留一交叉验证法进行模型拟合</h2><h1 id="使用留一交叉验证法进行模型拟合"><a href="#使用留一交叉验证法进行模型拟合" class="headerlink" title="使用留一交叉验证法进行模型拟合"></a>使用留一交叉验证法进行模型拟合</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loo = LeaveOneOut()</span><br><span class="line">scores_mse = -cross_val_score(model, X, y, cv=loo, scoring=&#x27;neg_mean_squared_error&#x27;)</span><br><span class="line">scores_mse.mean()  </span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sxdtlili.github.io/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/" data-id="cltzzz8pa0000k4cyhcj15w2z" data-title="线性回归算法" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2024/03/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">现代人工智能的基石——随机梯度下降法和误差反向传播</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/">算法实现</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B1%82%E5%AF%BC/" rel="tag">求导</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/%E6%B1%82%E5%AF%BC/" style="font-size: 10px;">求导</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/">线性回归算法</a>
          </li>
        
          <li>
            <a href="/2024/03/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">现代人工智能的基石——随机梯度下降法和误差反向传播</a>
          </li>
        
          <li>
            <a href="/2024/03/20/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 LiLi<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>