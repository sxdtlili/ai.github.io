<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>线性回归算法 | LiLi&#39;s Journey in Machine Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="第四章 线性回归算法1. 载入分析所需要的模块和函数#载入分析所需要的模块和函数import pandas as pd#载入pandas模块，并简称为pdimport numpy as np#载入numpy模块，并简称为npimport matplotlib.pyplot as plt#载入matplotlib.pyplot模块，并简称为pltimport seaborn as sns#载入sea">
<meta property="og:type" content="article">
<meta property="og:title" content="线性回归算法">
<meta property="og:url" content="https://sxdtlili.github.io/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="LiLi&#39;s Journey in Machine Learning">
<meta property="og:description" content="第四章 线性回归算法1. 载入分析所需要的模块和函数#载入分析所需要的模块和函数import pandas as pd#载入pandas模块，并简称为pdimport numpy as np#载入numpy模块，并简称为npimport matplotlib.pyplot as plt#载入matplotlib.pyplot模块，并简称为pltimport seaborn as sns#载入sea">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-03-20T16:05:18.000Z">
<meta property="article:modified_time" content="2024-03-20T16:07:44.014Z">
<meta property="article:author" content="LiLi">
<meta property="article:tag" content="线性回归">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="LiLi's Journey in Machine Learning" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LiLi&#39;s Journey in Machine Learning</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://sxdtlili.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-线性回归算法" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/" class="article-date">
  <time class="dt-published" datetime="2024-03-20T16:05:18.000Z" itemprop="datePublished">2024-03-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/">算法实现</a>►<a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      线性回归算法
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="第四章-线性回归算法"><a href="#第四章-线性回归算法" class="headerlink" title="第四章 线性回归算法"></a>第四章 线性回归算法</h1><h2 id="1-载入分析所需要的模块和函数"><a href="#1-载入分析所需要的模块和函数" class="headerlink" title="1. 载入分析所需要的模块和函数"></a>1. 载入分析所需要的模块和函数</h2><p>#载入分析所需要的模块和函数<br>import pandas as pd#载入pandas模块，并简称为pd<br>import numpy as np#载入numpy模块，并简称为np<br>import matplotlib.pyplot as plt#载入matplotlib.pyplot模块，并简称为plt<br>import seaborn as sns#载入seaborn模块，并简称为sns<br>from scipy import stats#载入stats模块<br>from scipy.stats import probplot#载入probplot模块<br>import statsmodels.formula.api as smf#载入statsmodels.formula.api模块，并简称为smf<br>from sklearn.linear_model import LinearRegression#载入LinearRegression模块<br>from sklearn.model_selection import train_test_split#载入train_test_split模块<br>from sklearn.metrics import mean_squared_error, r2_score#载入mean_squared_error, r2_score模块</p>
<h2 id="2-数据读取及观察"><a href="#2-数据读取及观察" class="headerlink" title="2. 数据读取及观察"></a>2. 数据读取及观察</h2><p>#习题1<br>#数据读取及观察<br>data&#x3D;pd.read_csv(‘D:&#x2F;2023-2024-1&#x2F;专业学习&#x2F;机器学习原理与算法实现&#x2F;Python机器学习原理与算法实现之PPT与源代码&#x2F;正文源代码及数据文件&#x2F;第四章 线性回归算法&#x2F;数据4.2.csv’)<br>data&#x3D; data.iloc[:, 1:5]#提取M0流通中现金，M1狭义货币，M2广义货币三列</p>
<h2 id="3-描述性分析"><a href="#3-描述性分析" class="headerlink" title="3. 描述性分析"></a>3. 描述性分析</h2><h3 id="3-1-对数据集进行描述性分析"><a href="#3-1-对数据集进行描述性分析" class="headerlink" title="3.1 对数据集进行描述性分析"></a>3.1 对数据集进行描述性分析</h3><p>#描述性分析<br>data.describe()#对数据集进行描述性分析</p>
<p>data.describe().round(2)#只保留两位小数</p>
<h3 id="3-2-对数据进行转置"><a href="#3-2-对数据进行转置" class="headerlink" title="3.2 对数据进行转置"></a>3.2 对数据进行转置</h3><p>data.describe().round(2).T#只保留两位小数并转置</p>
<h3 id="3-3-对数据集中的变量求均值"><a href="#3-3-对数据集中的变量求均值" class="headerlink" title="3.3 对数据集中的变量求均值"></a>3.3 对数据集中的变量求均值</h3><p>data.mean()#对数据集中的变量求均值</p>
<h3 id="3-4-对数据集中的变量求方差"><a href="#3-4-对数据集中的变量求方差" class="headerlink" title="3.4 对数据集中的变量求方差"></a>3.4 对数据集中的变量求方差</h3><p>data.var()#对数据集中的变量求方差</p>
<h3 id="3-5-对数据集中的变量求标准差"><a href="#3-5-对数据集中的变量求标准差" class="headerlink" title="3.5 对数据集中的变量求标准差"></a>3.5 对数据集中的变量求标准差</h3><p>data.std()#对数据集中的变量求标准差</p>
<h3 id="3-6-对数据集中的变量求协方差矩阵"><a href="#3-6-对数据集中的变量求协方差矩阵" class="headerlink" title="3.6 对数据集中的变量求协方差矩阵"></a>3.6 对数据集中的变量求协方差矩阵</h3><p>data.cov()#对数据集中的变量求协方差矩阵</p>
<h2 id="4-正态性检验"><a href="#4-正态性检验" class="headerlink" title="4. 正态性检验"></a>4. 正态性检验</h2><h3 id="4-1-Shapiro-Wilk-test检验"><a href="#4-1-Shapiro-Wilk-test检验" class="headerlink" title="4.1 Shapiro-Wilk test检验"></a>4.1 Shapiro-Wilk test检验</h3><p>#Shapiro-Wilk test检验<br>Ho &#x3D; ‘数据服从正态分布’#定义原假设<br>Ha &#x3D; ‘数据不服从正态分布’#定义备择假设<br>alpha &#x3D; 0.05#定义显著性P值<br>def normality_check(data):<br>    for columnName, columnData in data.items():<br>        print(“Shapiro test for {columnName}”.format(columnName&#x3D;columnName))<br>        res &#x3D; stats.shapiro(columnData)<br>        pValue &#x3D; round(res[1], 2)<br>        if pValue &gt; alpha:<br>            print(“pvalue &#x3D; {pValue} &gt; {alpha}. 不能拒绝原假设. {Ho}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ho&#x3D;Ho))<br>        else:<br>            print(“pvalue &#x3D; {pValue} &lt;&#x3D; {alpha}. 拒绝原假设. {Ha}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ha&#x3D;Ha))<br>normality_check(data)</p>
<h3 id="4-2-使用kstest检验数据是否服从正态分布"><a href="#4-2-使用kstest检验数据是否服从正态分布" class="headerlink" title="4.2 使用kstest检验数据是否服从正态分布"></a>4.2 使用kstest检验数据是否服从正态分布</h3><p>#使用kstest检验数据是否服从正态分布<br>Ho &#x3D; ‘数据服从正态分布’#定义原假设<br>Ha &#x3D; ‘数据不服从正态分布’#定义备择假设<br>alpha &#x3D; 0.05#定义显著性P值<br>def normality_check(data):<br>    for columnName, columnData in data.items():<br>        print(“kstest for {columnName}”.format(columnName&#x3D;columnName))<br>        res &#x3D; stats.kstest(columnData,’norm’)<br>        pValue &#x3D; round(res[1], 2)<br>        if pValue &gt; alpha:<br>            print(“pvalue &#x3D; {pValue} &gt; {alpha}. 不能拒绝原假设. {Ho}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ho&#x3D;Ho))<br>        else:<br>            print(“pvalue &#x3D; {pValue} &lt;&#x3D; {alpha}. 拒绝原假设. {Ha}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ha&#x3D;Ha))<br>normality_check(data)</p>
<h2 id="5-作图"><a href="#5-作图" class="headerlink" title="5 作图"></a>5 作图</h2><h3 id="5-1-直方图"><a href="#5-1-直方图" class="headerlink" title="5.1 直方图"></a>5.1 直方图</h3><h1 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h1><p>plt.figure(figsize&#x3D;(16, 9),dpi&#x3D;300)<br>sns.histplot(data[‘M0’],bins&#x3D;10,kde&#x3D;True)<br>plt.title(“Histogram of ‘M0’”)</p>
<p>plt.figure(figsize&#x3D;(16, 9),dpi&#x3D;300)<br>sns.histplot(data[‘M1’],bins&#x3D;10,kde&#x3D;True)<br>plt.title(“Histogram of ‘M1’”)</p>
<p>plt.figure(figsize&#x3D;(16, 9),dpi&#x3D;300)<br>sns.histplot(data[‘M2’],bins&#x3D;10,kde&#x3D;True)<br>plt.title(“Histogram of ‘M2’”)</p>
<h3 id="5-2-密度图"><a href="#5-2-密度图" class="headerlink" title="5.2 密度图"></a>5.2 密度图</h3><p>#密度图<br>plt.figure(figsize&#x3D;(12, 6),dpi&#x3D;300)<br>plt.subplot(1,3,1)#指定作图位置<br>sns.histplot(data[‘M0’], kde&#x3D;True)<br>plt.title(“Density distribution of ‘M0’”)<br>plt.subplot(1,3,2)#指定作图位置<br>sns.histplot(data[‘M1’], kde&#x3D;True)<br>plt.title(“Density distribution of ‘M1’”)<br>plt.subplot(1,3,3)#指定作图位置<br>sns.histplot(data[‘M2’], kde&#x3D;True)<br>plt.title(“Density distribution of ‘M2’”)</p>
<h3 id="5-3-箱线图"><a href="#5-3-箱线图" class="headerlink" title="5.3 箱线图"></a>5.3 箱线图</h3><p>#箱线图<br>plt.figure(figsize&#x3D;(14, 6),dpi&#x3D;300)<br>plt.subplot(1,3,1)#指定作图位置<br>plt.boxplot(data[‘M0’])<br>plt.title(“Boxlpot of ‘M0’”)<br>plt.subplot(1,3,2)#指定作图位置<br>plt.boxplot(data[‘M1’])<br>plt.title(“Boxlpot of ‘M1’”)<br>plt.subplot(1,3,3)#指定作图位置<br>plt.boxplot(data[‘M2’])<br>plt.title(“Boxlpot of ‘M2’”)</p>
<h3 id="5-4-小提琴图"><a href="#5-4-小提琴图" class="headerlink" title="5.4 小提琴图"></a>5.4 小提琴图</h3><p>#小提琴图<br>plt.figure(figsize&#x3D;(16, 6),dpi&#x3D;300)<br>plt.subplot(1,3,1)#指定作图位置<br>sns.violinplot(data[‘M0’])<br>plt.title(“Violin plot of ‘M0’”)<br>plt.subplot(1,3,2)#指定作图位置<br>sns.violinplot(data[‘M1’])<br>plt.title(“Violin plot of ‘M1’”)<br>plt.subplot(1,3,3)#指定作图位置<br>sns.violinplot(data[‘M2’])<br>plt.title(“Violin plot of ‘M2’”)</p>
<h3 id="5-5-正态-QQ-图"><a href="#5-5-正态-QQ-图" class="headerlink" title="5.5 正态 QQ 图"></a>5.5 正态 QQ 图</h3><p>#正态 QQ 图<br>plt.figure(figsize&#x3D;(16, 6),dpi&#x3D;300)<br>plt.subplot(1,3,1)#指定作图位置<br>probplot(data[‘M0’], plot&#x3D;plt)<br>plt.title(“Q-Q plot of ‘M0’”)<br>plt.subplot(1,3,2)#指定作图位置<br>probplot(data[‘M1’], plot&#x3D;plt)<br>plt.title(“Q-Q plot of ‘M1’”)<br>plt.subplot(1,3,3)#指定作图位置<br>probplot(data[‘M2’], plot&#x3D;plt)<br>plt.title(“Q-Q plot of ‘M2’”)</p>
<h3 id="5-6-散点图和点线图"><a href="#5-6-散点图和点线图" class="headerlink" title="5.6 散点图和点线图"></a>5.6 散点图和点线图</h3><h1 id="散点图和点线图"><a href="#散点图和点线图" class="headerlink" title="散点图和点线图"></a>散点图和点线图</h1><p>plt.figure(figsize&#x3D;(16,6),dpi&#x3D;300)#设定图形的宽为12英寸，图形的高为6英寸<br>plt.subplot(1,3,1)#指定作图位置。在同一画面创建1行3列个图形位置，首先在从左到右的第一个位置作图<br>sns.scatterplot(data&#x3D;data, x&#x3D;”M1”, y&#x3D;”M2”, hue&#x3D;”M1”, alpha&#x3D;0.6)<br>plt.title(“Scatter plot”)#将散点图的标题设定为Scatter plot</p>
<p>plt.subplot(1,3,2)#指定作图位置<br>sns.lineplot(data&#x3D;data, x&#x3D;”M1”, y&#x3D;”M2”)<br>plt.title(“Line plot of M1, M2”)</p>
<p>plt.subplot(1,3,3)#指定作图位置<br>sns.lineplot(data&#x3D;data)#绘制全部变量的线图<br>plt.title(‘Line Plot’)#将标题设定为Line Plot</p>
<h3 id="5-7-热力图"><a href="#5-7-热力图" class="headerlink" title="5.7 热力图"></a>5.7 热力图</h3><p>#热力图<br>plt.figure(figsize&#x3D;(10, 10),dpi&#x3D;300)#设置图形大小<br>plt.subplot(1, 2, 1)#指定作图位置<br>sns.heatmap(data&#x3D;data, cmap&#x3D;”YlGnBu”, annot &#x3D; True)#基于data数据绘制热力图，cmap&#x3D;”YlGnBu”用来设置热力图的颜色色系，annot&#x3D;True表示在热力图每个方格写入数据。<br>plt.title(“Heatmap using seaborn”)#指定作图标题<br>plt.subplot(1, 2, 2)#指定作图位置<br>plt.imshow(data, cmap &#x3D;”YlGnBu”)#实现热图绘制<br>plt.title(“Heatmap using matplotlib”)#指定作图标题</p>
<h2 id="6-回归拟合图"><a href="#6-回归拟合图" class="headerlink" title="6 回归拟合图"></a>6 回归拟合图</h2><p>#回归拟合图<br>plt.figure(figsize&#x3D;(10, 10),dpi&#x3D;300)#设置图形大小<br>sns.regplot( x&#x3D;”M0”, y&#x3D;”M1”,data&#x3D;data )</p>
<h2 id="7-联合分布图"><a href="#7-联合分布图" class="headerlink" title="7 联合分布图"></a>7 联合分布图</h2><p>#联合分布图<br>plt.figure(figsize&#x3D;(8, 6),dpi&#x3D;100)#设置图形大小<br>sns.jointplot(x &#x3D; “M0”, y &#x3D; “M1”, kind &#x3D; “reg”, data &#x3D; data)<br>plt.title(“Joint plot using sns”)#为图表设置标题</p>
<p>#习题2<br>#数据读取及观察<br>data&#x3D;pd.read_csv(‘D:&#x2F;2023-2024-1&#x2F;专业学习&#x2F;机器学习原理与算法实现&#x2F;Python机器学习原理与算法实现之PPT与源代码&#x2F;正文源代码及数据文件&#x2F;第四章 线性回归算法&#x2F;数据4.3.csv’)<br>data&#x3D; data.iloc[:, 1:6]#提取Profit contribution，Net interest income，Intermediate income，Deposit and finance daily列</p>
<p>#描述性分析<br>data.describe()#对数据集进行描述性分析</p>
<p>data.describe().round(2)#只保留两位小数</p>
<p>data.describe().round(2).T#只保留两位小数并转置</p>
<p>data.mean()#对数据集中的变量求均值</p>
<p>data.var()#对数据集中的变量求方差</p>
<p>data.std()#对数据集中的变量求标准差</p>
<p>data.cov()#对数据集中的变量求协方差矩阵</p>
<p>#Shapiro-Wilk test检验<br>Ho &#x3D; ‘数据服从正态分布’#定义原假设<br>Ha &#x3D; ‘数据不服从正态分布’#定义备择假设<br>alpha &#x3D; 0.05#定义显著性P值<br>def normality_check(data):<br>    for columnName, columnData in data.items():<br>        print(“Shapiro test for {columnName}”.format(columnName&#x3D;columnName))<br>        res &#x3D; stats.shapiro(columnData)<br>        pValue &#x3D; round(res[1], 2)<br>        if pValue &gt; alpha:<br>            print(“pvalue &#x3D; {pValue} &gt; {alpha}. 不能拒绝原假设. {Ho}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ho&#x3D;Ho))<br>        else:<br>            print(“pvalue &#x3D; {pValue} &lt;&#x3D; {alpha}. 拒绝原假设. {Ha}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ha&#x3D;Ha))<br>normality_check(data)</p>
<p>#使用kstest检验数据是否服从正态分布<br>Ho &#x3D; ‘数据服从正态分布’#定义原假设<br>Ha &#x3D; ‘数据不服从正态分布’#定义备择假设<br>alpha &#x3D; 0.05#定义显著性P值<br>def normality_check(data):<br>    for columnName, columnData in data.items():<br>        print(“kstest for {columnName}”.format(columnName&#x3D;columnName))<br>        res &#x3D; stats.kstest(columnData,’norm’)<br>        pValue &#x3D; round(res[1], 2)<br>        if pValue &gt; alpha:<br>            print(“pvalue &#x3D; {pValue} &gt; {alpha}. 不能拒绝原假设. {Ho}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ho&#x3D;Ho))<br>        else:<br>            print(“pvalue &#x3D; {pValue} &lt;&#x3D; {alpha}. 拒绝原假设. {Ha}”.format(pValue&#x3D;pValue, alpha&#x3D;alpha, Ha&#x3D;Ha))<br>normality_check(data)</p>
<h2 id="8-相关性分析"><a href="#8-相关性分析" class="headerlink" title="8 相关性分析"></a>8 相关性分析</h2><h3 id="8-1-皮尔逊相关系数矩阵"><a href="#8-1-皮尔逊相关系数矩阵" class="headerlink" title="8.1 皮尔逊相关系数矩阵"></a>8.1 皮尔逊相关系数矩阵</h3><p>#相关性分析<br>pd.set_option(‘display.max_rows’, None)#显示完整的行，如果不运行该代码，那么结果的行可能会显示不全，中间有省略号。<br>pd.set_option(‘display.max_columns’, None)#显示完整的列，如果不运行该代码，那么结果的列可能会显示不全，中间有省略号。<br>print(data.corr(method&#x3D;’pearson’)) #输出变量之间的皮尔逊相关系数矩阵</p>
<h3 id="8-2-绘制相关矩阵的热图"><a href="#8-2-绘制相关矩阵的热图" class="headerlink" title="8.2 绘制相关矩阵的热图"></a>8.2 绘制相关矩阵的热图</h3><p>plt.figure(figsize&#x3D;(8, 6),dpi&#x3D;100)#设置图形大小<br>plt.subplot(1,1,1)<br>sns.heatmap(data.corr(), annot&#x3D;True)# 绘制相关矩阵的热图</p>
<h3 id="8-3-斯皮尔曼等级相关系数矩阵"><a href="#8-3-斯皮尔曼等级相关系数矩阵" class="headerlink" title="8.3 斯皮尔曼等级相关系数矩阵"></a>8.3 斯皮尔曼等级相关系数矩阵</h3><p>print(data.corr(method&#x3D;’spearman’)) #输出变量之间的斯皮尔曼等级相关系数矩阵</p>
<h3 id="8-4-肯德尔等级相关系数矩阵"><a href="#8-4-肯德尔等级相关系数矩阵" class="headerlink" title="8.4 肯德尔等级相关系数矩阵"></a>8.4 肯德尔等级相关系数矩阵</h3><p>print(data.corr(method&#x3D;’kendall’)) #输出变量之间的肯德尔等级相关系数矩阵</p>
<h2 id="9-使用-smf-进行线性回归"><a href="#9-使用-smf-进行线性回归" class="headerlink" title="9 使用 smf 进行线性回归"></a>9 使用 smf 进行线性回归</h2><p>#使用 smf 进行线性回归<br>X &#x3D; data.iloc[:, 1:5]<br>y &#x3D; data.iloc[:, 0:1]<br>model &#x3D; smf.ols(‘y~X’, data&#x3D;data).fit()#使用线性回归模型，并进行训练<br>print(model.summary())#输出估计模型摘要</p>
<p>这是一个OLS（普通最小二乘法）回归结果的摘要。OLS是一种用于估计回归模型参数的统计方法。</p>
<ol>
<li>R-squared（R平方）: 0.279，这表示模型可以解释因变量变化的27.9%。</li>
<li>Adj. R-squared（调整后的R平方）: 0.278，这是对R平方的修正，考虑了模型中自变量的数量和样本量的影响。</li>
<li>F-statistic（F统计量）: 1086.0，用于检验模型的整体显著性。</li>
<li>Prob (F-statistic)（F统计量的概率）: 0.00，表示模型的整体显著性的概率。</li>
<li>coef（系数）列包含了每个自变量的系数估计值，std err列是系数的标准误差。</li>
<li>P&gt;|t|列显示了每个系数的显著性，即它们是否显著地不同于零。</li>
<li>Omnibus（奥姆尼巴斯）: 26383.785，用于检验误差项的正态性。</li>
<li>Prob(Omnibus)（奥姆尼巴斯的概率）: 0.000，表示误差项正态性的概率。</li>
<li>Skew（偏度）: -48.654，表示因变量的偏度。</li>
<li>Kurtosis（峰度）: 3222.836，表示因变量的峰度。</li>
<li>Durbin-Watson（杜宾-沃森统计量）: 1.999，用于检验误差项之间的自相关性。</li>
<li>Jarque-Bera（雅可比-贝拉）: 3649612011.153，用于检验误差项的正态性。</li>
<li>Cond. No.（条件数）: 3.87e+07，用于检验自变量之间的多重共线性。<br>– 需要注意的是，标准误差假设误差项的协方差矩阵被正确地指定。条件数很大可能表明存在严重的多重共线性或其他数值问题。</li>
</ol>
<h2 id="10-多重共线性检验"><a href="#10-多重共线性检验" class="headerlink" title="10 多重共线性检验"></a>10 多重共线性检验</h2><p>#多重共线性检验<br>from statsmodels.stats.outliers_influence import variance_inflation_factor<br>vif &#x3D; pd.DataFrame()<br>vif[“VIF Factor”] &#x3D; [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]<br>vif[“features”] &#x3D; X.columns<br>vif.round(1)</p>
<h2 id="11-使用-sklearn-进行线性回归"><a href="#11-使用-sklearn-进行线性回归" class="headerlink" title="11 使用 sklearn 进行线性回归"></a>11 使用 sklearn 进行线性回归</h2><h3 id="11-1-使用验证集法进行模型拟合"><a href="#11-1-使用验证集法进行模型拟合" class="headerlink" title="11.1 使用验证集法进行模型拟合"></a>11.1 使用验证集法进行模型拟合</h3><p>#使用 sklearn 进行线性回归<br>#使用验证集法进行模型拟合<br>X &#x3D; data.iloc[:, 1:5]<br>y &#x3D; data.iloc[:, 0:1]<br>X_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, test_size&#x3D;0.3, random_state&#x3D;50)#将样本示例全集划分为训练样本和测试样本，测试样本占比为30%。<br>X_train.shape, X_test.shape, y_train.shape, y_test.shape#观察四个数据的形状<br>model &#x3D; LinearRegression()#使用线性回归模型<br>model.fit(X_train, y_train)#基于训练样本拟合模型</p>
<h3 id="11-2-计算回归系数值"><a href="#11-2-计算回归系数值" class="headerlink" title="11.2 计算回归系数值"></a>11.2 计算回归系数值</h3><p>model.coef_#计算上步估计得到的回归系数值</p>
<h3 id="11-3-模型在训练集中的拟合优度（可决系数）"><a href="#11-3-模型在训练集中的拟合优度（可决系数）" class="headerlink" title="11.3 模型在训练集中的拟合优度（可决系数）"></a>11.3 模型在训练集中的拟合优度（可决系数）</h3><p>model.score(X_train, y_train)#观察模型在训练集中的拟合优度（可决系数）</p>
<h3 id="11-4-响应变量基于测试集的预测结果"><a href="#11-4-响应变量基于测试集的预测结果" class="headerlink" title="11.4 响应变量基于测试集的预测结果"></a>11.4 响应变量基于测试集的预测结果</h3><p>pred &#x3D; model.predict(X_test)#计算响应变量基于测试集的预测结果<br>pred.shape#观察数据形状</p>
<h3 id="11-5-测试集的均方误差"><a href="#11-5-测试集的均方误差" class="headerlink" title="11.5 测试集的均方误差"></a>11.5 测试集的均方误差</h3><p>mean_squared_error(y_test, pred)#计算测试集的均方误差</p>
<h3 id="11-6-计算测试集的可决系数"><a href="#11-6-计算测试集的可决系数" class="headerlink" title="11.6 计算测试集的可决系数"></a>11.6 计算测试集的可决系数</h3><p>r2_score(y_test, pred)#计算测试集的可决系数</p>
<h3 id="11-7-更换随机数种子，使用验证集法进行模型拟合"><a href="#11-7-更换随机数种子，使用验证集法进行模型拟合" class="headerlink" title="11.7 更换随机数种子，使用验证集法进行模型拟合"></a>11.7 更换随机数种子，使用验证集法进行模型拟合</h3><p>#更换随机数种子，使用验证集法进行模型拟合<br>X_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, test_size&#x3D;0.3, random_state&#x3D;100)#更换随机数种子<br>model &#x3D; LinearRegression().fit(X_train, y_train)#基于训练样本拟合线性回归模型<br>pred &#x3D; model.predict(X_test)#计算响应变量基于测试集的预测结果<br>mean_squared_error(y_test, pred)#计算测试集的均方误差</p>
<p>r2_score(y_test, pred)#计算测试集的可决系数</p>
<h2 id="12-使用10折交叉验证法进行模型拟合"><a href="#12-使用10折交叉验证法进行模型拟合" class="headerlink" title="12 使用10折交叉验证法进行模型拟合"></a>12 使用10折交叉验证法进行模型拟合</h2><h3 id="12-1-使用10折交叉验证法进行模型拟合"><a href="#12-1-使用10折交叉验证法进行模型拟合" class="headerlink" title="12.1 使用10折交叉验证法进行模型拟合"></a>12.1 使用10折交叉验证法进行模型拟合</h3><h1 id="使用10折交叉验证法进行模型拟合"><a href="#使用10折交叉验证法进行模型拟合" class="headerlink" title="使用10折交叉验证法进行模型拟合"></a>使用10折交叉验证法进行模型拟合</h1><p>from sklearn.model_selection import KFold<br>from sklearn.model_selection import cross_val_score<br>from sklearn.model_selection import LeaveOneOut<br>from sklearn.model_selection import RepeatedKFold<br>X &#x3D; data.iloc[:, 1:5]<br>y &#x3D; data.iloc[:, 0:1]<br>model &#x3D; LinearRegression()#使用线性回归模型<br>kfold &#x3D; KFold(n_splits&#x3D;10,shuffle&#x3D;True, random_state&#x3D;1)#将样本示例全集分为10折<br>scores &#x3D; cross_val_score(model, X, y, cv&#x3D;kfold)#计算每一折的可决系数</p>
<h3 id="12-2-显示每一折的可决系数"><a href="#12-2-显示每一折的可决系数" class="headerlink" title="12.2 显示每一折的可决系数"></a>12.2 显示每一折的可决系数</h3><p>scores#显示每一折的可决系数</p>
<h3 id="12-3-计算各折样本可决系数的均值"><a href="#12-3-计算各折样本可决系数的均值" class="headerlink" title="12.3 计算各折样本可决系数的均值"></a>12.3 计算各折样本可决系数的均值</h3><p>scores.mean()#计算各折样本可决系数的均值</p>
<h3 id="12-4-计算各折样本可决系数的标准差"><a href="#12-4-计算各折样本可决系数的标准差" class="headerlink" title="12.4 计算各折样本可决系数的标准差"></a>12.4 计算各折样本可决系数的标准差</h3><p>scores.std()#计算各折样本可决系数的标准差</p>
<h3 id="12-5-显示各折样本的均方误差"><a href="#12-5-显示各折样本的均方误差" class="headerlink" title="12.5 显示各折样本的均方误差"></a>12.5 显示各折样本的均方误差</h3><p>scores_mse &#x3D; -cross_val_score(model, X, y, cv&#x3D;kfold, scoring&#x3D;’neg_mean_squared_error’)#得到每个子样本的均方误差<br>scores_mse#显示各折样本的均方误差</p>
<h3 id="12-6-各折样本均方误差的均值"><a href="#12-6-各折样本均方误差的均值" class="headerlink" title="12.6 各折样本均方误差的均值"></a>12.6 各折样本均方误差的均值</h3><p>scores_mse.mean()#计算各折样本均方误差的均值</p>
<h3 id="12-7-更换随机数种子观察均方误差MSE大小"><a href="#12-7-更换随机数种子观察均方误差MSE大小" class="headerlink" title="12.7 更换随机数种子观察均方误差MSE大小"></a>12.7 更换随机数种子观察均方误差MSE大小</h3><h1 id="更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小"><a href="#更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小" class="headerlink" title="更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小"></a>更换随机数种子，并与上步得到结果进行对比，观察均方误差MSE大小</h1><p>kfold &#x3D; KFold(n_splits&#x3D;10, shuffle&#x3D;True, random_state&#x3D;100)<br>scores_mse &#x3D; -cross_val_score(model, X, y, cv&#x3D;kfold, scoring&#x3D;’neg_mean_squared_error’)#得到每个子样本的均方误差<br>scores_mse.mean()#计算各折样本均方误差的均值</p>
<h2 id="13-使用10折重复10次交叉验证法进行模型拟合"><a href="#13-使用10折重复10次交叉验证法进行模型拟合" class="headerlink" title="13 使用10折重复10次交叉验证法进行模型拟合"></a>13 使用10折重复10次交叉验证法进行模型拟合</h2><p>#使用10折重复10次交叉验证法进行模型拟合<br>rkfold &#x3D; RepeatedKFold(n_splits&#x3D;10, n_repeats&#x3D;10, random_state&#x3D;1)<br>scores_mse &#x3D; -cross_val_score(model, X, y, cv&#x3D;rkfold, scoring&#x3D;’neg_mean_squared_error’)#得到每个子样本的均方误差<br>scores_mse.shape</p>
<p>scores_mse.mean()</p>
<h2 id="14-使用留一交叉验证法进行模型拟合"><a href="#14-使用留一交叉验证法进行模型拟合" class="headerlink" title="14 使用留一交叉验证法进行模型拟合"></a>14 使用留一交叉验证法进行模型拟合</h2><h1 id="使用留一交叉验证法进行模型拟合"><a href="#使用留一交叉验证法进行模型拟合" class="headerlink" title="使用留一交叉验证法进行模型拟合"></a>使用留一交叉验证法进行模型拟合</h1><p>loo &#x3D; LeaveOneOut()<br>scores_mse &#x3D; -cross_val_score(model, X, y, cv&#x3D;loo, scoring&#x3D;’neg_mean_squared_error’)<br>scores_mse.mean()  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sxdtlili.github.io/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/" data-id="cltzzz8pa0000k4cyhcj15w2z" data-title="线性回归算法" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2024/03/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">现代人工智能的基石——随机梯度下降法和误差反向传播</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/">算法实现</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B1%82%E5%AF%BC/" rel="tag">求导</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/%E6%B1%82%E5%AF%BC/" style="font-size: 10px;">求导</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/03/21/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/">线性回归算法</a>
          </li>
        
          <li>
            <a href="/2024/03/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">现代人工智能的基石——随机梯度下降法和误差反向传播</a>
          </li>
        
          <li>
            <a href="/2024/03/20/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 LiLi<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>